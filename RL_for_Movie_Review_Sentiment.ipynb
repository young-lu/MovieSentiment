{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_for_Movie_Review_Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9jeO33X-Rudc",
        "2yM2pHz2xfXF",
        "wb1fCqlMxvII",
        "d7Rv8Wdlwvzh",
        "bQCcK5Xk_GdM",
        "KJ6VJNc18lEY",
        "RjdSfRXDdAlu",
        "V7EwxU0DdEhj",
        "8uPcfpU8Ko15"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMU2ap9mfFBMWMA4RppD1uo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f827e42bfccf426897920ed6a6a7cab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd590982f9ae41dda6f72ebbaf0e0dd7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d860b8f962da4fecaf0b8c98977d3e9b",
              "IPY_MODEL_623cda3ac6bc438f89a3f69ee3751a0d"
            ]
          }
        },
        "bd590982f9ae41dda6f72ebbaf0e0dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d860b8f962da4fecaf0b8c98977d3e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42c704118ee84ea9a6ef5a084f659fb8",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfe1d979e955468093cb97def3aa36c5"
          }
        },
        "623cda3ac6bc438f89a3f69ee3751a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_807193d492614d2cbd42dd3a93af0a99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:01&lt;00:00,  1.82s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6119a00779284ab886df6d6b969f2d1f"
          }
        },
        "42c704118ee84ea9a6ef5a084f659fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfe1d979e955468093cb97def3aa36c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "807193d492614d2cbd42dd3a93af0a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6119a00779284ab886df6d6b969f2d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b21e52fc9354611945c940c60021ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_222ca9be4b784afea651525fca4f70ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20c7e7f182e743aa8b7cbd51294e1180",
              "IPY_MODEL_ba542919da5a43a7b44d3382dc7afb71"
            ]
          }
        },
        "222ca9be4b784afea651525fca4f70ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20c7e7f182e743aa8b7cbd51294e1180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afcdb1e07a474b87a76d6b7bfd2cf9f5",
            "_dom_classes": [],
            "description": "Dl Size...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ead66a8d3194ca88c24622aabe05553"
          }
        },
        "ba542919da5a43a7b44d3382dc7afb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62adb1f8f25f40bb8aa5ee06e58ad816",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/80 [00:01&lt;00:00, 44.62 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73c86fa04b6048acb8207728c6e25196"
          }
        },
        "afcdb1e07a474b87a76d6b7bfd2cf9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ead66a8d3194ca88c24622aabe05553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62adb1f8f25f40bb8aa5ee06e58ad816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73c86fa04b6048acb8207728c6e25196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b219f021a1174692a0c16daf1ee07fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eba1e2d602214d06bb1ca03b20b66e49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a28cc1b56aa84c918b7c12313d475d8f",
              "IPY_MODEL_7e687fe5dea94ebbbec09cbfa8343b13"
            ]
          }
        },
        "eba1e2d602214d06bb1ca03b20b66e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a28cc1b56aa84c918b7c12313d475d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1866a2f2ce4e44558fb7f2b618f3dfc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b8fa227d3d040399588368ff1fb1f38"
          }
        },
        "7e687fe5dea94ebbbec09cbfa8343b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e849004a4404f909e86764ce9dd3a7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/0 [00:12&lt;00:00, 3481.41 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4459cb8ce0c94de2bc482fc0868d1dad"
          }
        },
        "1866a2f2ce4e44558fb7f2b618f3dfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b8fa227d3d040399588368ff1fb1f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e849004a4404f909e86764ce9dd3a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4459cb8ce0c94de2bc482fc0868d1dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddfd1bcd0f6d4f2ba35c803a59248700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3001ba8540849deb162e307c50296f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae5711b3ca4c462aac92e72b44dc77c3",
              "IPY_MODEL_52fe4afeeae44f6082c09742894b3b50"
            ]
          }
        },
        "b3001ba8540849deb162e307c50296f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae5711b3ca4c462aac92e72b44dc77c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc3aec1cd3bd47709b9bfe6bf76dcebd",
            "_dom_classes": [],
            "description": " 52%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13037,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3239e41ad0c4432eb7a3adc2f9b3ebbf"
          }
        },
        "52fe4afeeae44f6082c09742894b3b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec755c836f4d454fbe1f60d1a51578a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13037/25000 [00:00&lt;00:00, 130369.50 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a459a1bc930e48648051100289095d89"
          }
        },
        "bc3aec1cd3bd47709b9bfe6bf76dcebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3239e41ad0c4432eb7a3adc2f9b3ebbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec755c836f4d454fbe1f60d1a51578a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a459a1bc930e48648051100289095d89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fb2dc161121485196715ec372b6686d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a804b2e8cdd54a9f9a95dd12dae4fae3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a07a12f4b59c4baba64d03cb176fb8cf",
              "IPY_MODEL_a5afe97a2b174de8a724e78cdf4dc5bd"
            ]
          }
        },
        "a804b2e8cdd54a9f9a95dd12dae4fae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a07a12f4b59c4baba64d03cb176fb8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92cffcc9673e4fa290030d22a57d8c43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ca9559997da4bbea730f482885f8a85"
          }
        },
        "a5afe97a2b174de8a724e78cdf4dc5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f81983c801614e57bec21f3ad53d7c05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/0 [00:12&lt;00:00, 3464.12 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_740b0be896934dad9856b7b7399b017f"
          }
        },
        "92cffcc9673e4fa290030d22a57d8c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ca9559997da4bbea730f482885f8a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f81983c801614e57bec21f3ad53d7c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "740b0be896934dad9856b7b7399b017f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6d9f8c9df314007aa9b1249d2dbf611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4cddb077c5ac4164b8e9bcc0f594d6a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b18748cbd1a42daa29499db01feb188",
              "IPY_MODEL_6a6c18b1ba544e69ba91ed4c30cf63ce"
            ]
          }
        },
        "4cddb077c5ac4164b8e9bcc0f594d6a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b18748cbd1a42daa29499db01feb188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e710c5c283649c497209ef1648a7d5e",
            "_dom_classes": [],
            "description": " 47%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11657,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9f46cf993394032b871662257e97c36"
          }
        },
        "6a6c18b1ba544e69ba91ed4c30cf63ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5418f1ce7cd749deadd9d54dc4e5c4fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11657/25000 [00:00&lt;00:00, 116566.50 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bda2a2e4cd94c2ebba06d065656b774"
          }
        },
        "9e710c5c283649c497209ef1648a7d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9f46cf993394032b871662257e97c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5418f1ce7cd749deadd9d54dc4e5c4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bda2a2e4cd94c2ebba06d065656b774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "692bc773cf4145a791630b029fd55e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a437c9ab110345b98e57c6697c3953bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b4e31e99f074c06b40eb7ba980e36a5",
              "IPY_MODEL_2a6306bd3654448d89dd2c9510250c44"
            ]
          }
        },
        "a437c9ab110345b98e57c6697c3953bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b4e31e99f074c06b40eb7ba980e36a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c25a54b1425429aad66d1aaa83fdcd2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_333d271189154ce5bfd4cda7582449bc"
          }
        },
        "2a6306bd3654448d89dd2c9510250c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41d0ee2638c54754af7815b9cc4fbeea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50000/0 [00:18&lt;00:00, 3394.95 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fded1f5f373a4ffca596bb355eee5b1d"
          }
        },
        "9c25a54b1425429aad66d1aaa83fdcd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "333d271189154ce5bfd4cda7582449bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41d0ee2638c54754af7815b9cc4fbeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fded1f5f373a4ffca596bb355eee5b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "120f2847f0c941059b4062764eda5ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec8af8ecba75424aa4e3f4ca9108e65c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_576808be55f94cdf8572bcf7ae1c16ca",
              "IPY_MODEL_0d39315dd3da40bfb2f90131944e7a17"
            ]
          }
        },
        "ec8af8ecba75424aa4e3f4ca9108e65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "576808be55f94cdf8572bcf7ae1c16ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05edc8400d9142ca8195509a12e07ac7",
            "_dom_classes": [],
            "description": " 63%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31484,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42db072214e84875a2b59b300e6d4092"
          }
        },
        "0d39315dd3da40bfb2f90131944e7a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_742f87a9dead42ca8c4523f4e19f9bbf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31484/50000 [00:04&lt;00:00, 58653.86 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_769ed69a444f49de98cf8d59928de589"
          }
        },
        "05edc8400d9142ca8195509a12e07ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42db072214e84875a2b59b300e6d4092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "742f87a9dead42ca8c4523f4e19f9bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "769ed69a444f49de98cf8d59928de589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-lu/MovieSentiment/blob/main/RL_for_Movie_Review_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvJ_liSIjjFg"
      },
      "source": [
        "# TF RL Model\n",
        "\n",
        "*    Policy Gradient with LSTM/BERT model\n",
        "*    comparison to normal BERT fine tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNRL0cDjS6E"
      },
      "source": [
        "### basic classification fine-tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-GdbMc6qA6"
      },
      "source": [
        "# from nltk import sent_tokenize as sentence_tokenize\n",
        "# import transformers\n",
        "# from transformers import BertTokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8YaM_FlCRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23eaf38-cf9a-473f-e9c1-8066d3e6682e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.10.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412,
          "referenced_widgets": [
            "f827e42bfccf426897920ed6a6a7cab2",
            "bd590982f9ae41dda6f72ebbaf0e0dd7",
            "d860b8f962da4fecaf0b8c98977d3e9b",
            "623cda3ac6bc438f89a3f69ee3751a0d",
            "42c704118ee84ea9a6ef5a084f659fb8",
            "dfe1d979e955468093cb97def3aa36c5",
            "807193d492614d2cbd42dd3a93af0a99",
            "6119a00779284ab886df6d6b969f2d1f",
            "4b21e52fc9354611945c940c60021ebb",
            "222ca9be4b784afea651525fca4f70ad",
            "20c7e7f182e743aa8b7cbd51294e1180",
            "ba542919da5a43a7b44d3382dc7afb71",
            "afcdb1e07a474b87a76d6b7bfd2cf9f5",
            "8ead66a8d3194ca88c24622aabe05553",
            "62adb1f8f25f40bb8aa5ee06e58ad816",
            "73c86fa04b6048acb8207728c6e25196",
            "b219f021a1174692a0c16daf1ee07fb1",
            "eba1e2d602214d06bb1ca03b20b66e49",
            "a28cc1b56aa84c918b7c12313d475d8f",
            "7e687fe5dea94ebbbec09cbfa8343b13",
            "1866a2f2ce4e44558fb7f2b618f3dfc9",
            "6b8fa227d3d040399588368ff1fb1f38",
            "7e849004a4404f909e86764ce9dd3a7e",
            "4459cb8ce0c94de2bc482fc0868d1dad",
            "ddfd1bcd0f6d4f2ba35c803a59248700",
            "b3001ba8540849deb162e307c50296f8",
            "ae5711b3ca4c462aac92e72b44dc77c3",
            "52fe4afeeae44f6082c09742894b3b50",
            "bc3aec1cd3bd47709b9bfe6bf76dcebd",
            "3239e41ad0c4432eb7a3adc2f9b3ebbf",
            "ec755c836f4d454fbe1f60d1a51578a9",
            "a459a1bc930e48648051100289095d89",
            "2fb2dc161121485196715ec372b6686d",
            "a804b2e8cdd54a9f9a95dd12dae4fae3",
            "a07a12f4b59c4baba64d03cb176fb8cf",
            "a5afe97a2b174de8a724e78cdf4dc5bd",
            "92cffcc9673e4fa290030d22a57d8c43",
            "5ca9559997da4bbea730f482885f8a85",
            "f81983c801614e57bec21f3ad53d7c05",
            "740b0be896934dad9856b7b7399b017f",
            "d6d9f8c9df314007aa9b1249d2dbf611",
            "4cddb077c5ac4164b8e9bcc0f594d6a0",
            "4b18748cbd1a42daa29499db01feb188",
            "6a6c18b1ba544e69ba91ed4c30cf63ce",
            "9e710c5c283649c497209ef1648a7d5e",
            "e9f46cf993394032b871662257e97c36",
            "5418f1ce7cd749deadd9d54dc4e5c4fa",
            "1bda2a2e4cd94c2ebba06d065656b774",
            "692bc773cf4145a791630b029fd55e26",
            "a437c9ab110345b98e57c6697c3953bf",
            "0b4e31e99f074c06b40eb7ba980e36a5",
            "2a6306bd3654448d89dd2c9510250c44",
            "9c25a54b1425429aad66d1aaa83fdcd2",
            "333d271189154ce5bfd4cda7582449bc",
            "41d0ee2638c54754af7815b9cc4fbeea",
            "fded1f5f373a4ffca596bb355eee5b1d",
            "120f2847f0c941059b4062764eda5ab2",
            "ec8af8ecba75424aa4e3f4ca9108e65c",
            "576808be55f94cdf8572bcf7ae1c16ca",
            "0d39315dd3da40bfb2f90131944e7a17",
            "05edc8400d9142ca8195509a12e07ac7",
            "42db072214e84875a2b59b300e6d4092",
            "742f87a9dead42ca8c4523f4e19f9bbf",
            "769ed69a444f49de98cf8d59928de589"
          ]
        },
        "id": "IcutlDDhj-YA",
        "outputId": "27a510ad-e3b8-4d35-dc35-131168ada64f"
      },
      "source": [
        "train_data, test_data = tfds.load('imdb_reviews', split=[\"train\", \"test\"], \n",
        "                                  batch_size=-1, as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f827e42bfccf426897920ed6a6a7cab2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progreâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b21e52fc9354611945c940c60021ebb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressStyâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b219f021a1174692a0c16daf1ee07fb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteFXP5IQ/imdb_reviews-train.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddfd1bcd0f6d4f2ba35c803a59248700",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fb2dc161121485196715ec372b6686d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteFXP5IQ/imdb_reviews-test.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d9f8c9df314007aa9b1249d2dbf611",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "692bc773cf4145a791630b029fd55e26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteFXP5IQ/imdb_reviews-unsupervised.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "120f2847f0c941059b4062764eda5ab2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\ndataset, info = tfds.load('imdb_reviews', with_info=True,\\n                          as_supervised=True)\\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\\n\\ntrain_dataset.element_spec\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ndjX-tkc3o",
        "outputId": "9e37666b-7e86-4384-a88a-1b661c986bb5"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", output_shape=[20], input_shape=[], dtype=tf.string, trainable=True)\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam',loss=tf.losses.BinaryCrossentropy(from_logits=True),metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 20)                400020    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                336       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 400,373\n",
            "Trainable params: 400,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oAuC99UTz6Q"
      },
      "source": [
        "x_val = train_examples[:10000]\n",
        "partial_x_train = train_examples[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2sbZk1TaIbO",
        "outputId": "a27aa5f5-d6cf-483c-f37b-f53e56827ac8"
      },
      "source": [
        "type(x_val)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcm2ugMIT00Q",
        "outputId": "a1a7c8f7-8e97-4728-a97a-2eb01e3989ba"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 2s 58ms/step - loss: 0.7434 - accuracy: 0.5263 - val_loss: 0.6633 - val_accuracy: 0.5984\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.6431 - accuracy: 0.6335 - val_loss: 0.6200 - val_accuracy: 0.6558\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.5964 - accuracy: 0.6854 - val_loss: 0.5812 - val_accuracy: 0.7020\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.5518 - accuracy: 0.7329 - val_loss: 0.5427 - val_accuracy: 0.7397\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.5066 - accuracy: 0.7675 - val_loss: 0.5054 - val_accuracy: 0.7648\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.4641 - accuracy: 0.8007 - val_loss: 0.4697 - val_accuracy: 0.7917\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.4224 - accuracy: 0.8262 - val_loss: 0.4388 - val_accuracy: 0.8044\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.3857 - accuracy: 0.8465 - val_loss: 0.4139 - val_accuracy: 0.8184\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.3529 - accuracy: 0.8626 - val_loss: 0.3909 - val_accuracy: 0.8275\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.3243 - accuracy: 0.8771 - val_loss: 0.3707 - val_accuracy: 0.8400\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.2980 - accuracy: 0.8879 - val_loss: 0.3551 - val_accuracy: 0.8478\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2757 - accuracy: 0.8979 - val_loss: 0.3427 - val_accuracy: 0.8534\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2560 - accuracy: 0.9048 - val_loss: 0.3354 - val_accuracy: 0.8575\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2393 - accuracy: 0.9113 - val_loss: 0.3276 - val_accuracy: 0.8617\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2225 - accuracy: 0.9203 - val_loss: 0.3186 - val_accuracy: 0.8658\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2075 - accuracy: 0.9264 - val_loss: 0.3140 - val_accuracy: 0.8685\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.1945 - accuracy: 0.9307 - val_loss: 0.3102 - val_accuracy: 0.8704\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.1828 - accuracy: 0.9369 - val_loss: 0.3125 - val_accuracy: 0.8715\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1715 - accuracy: 0.9411 - val_loss: 0.3064 - val_accuracy: 0.8736\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1611 - accuracy: 0.9448 - val_loss: 0.3062 - val_accuracy: 0.8738\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1510 - accuracy: 0.9511 - val_loss: 0.3061 - val_accuracy: 0.8756\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1422 - accuracy: 0.9555 - val_loss: 0.3100 - val_accuracy: 0.8746\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.1333 - accuracy: 0.9596 - val_loss: 0.3091 - val_accuracy: 0.8752\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1259 - accuracy: 0.9630 - val_loss: 0.3108 - val_accuracy: 0.8756\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.1183 - accuracy: 0.9659 - val_loss: 0.3147 - val_accuracy: 0.8749\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.1111 - accuracy: 0.9683 - val_loss: 0.3160 - val_accuracy: 0.8746\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.1035 - accuracy: 0.9722 - val_loss: 0.3189 - val_accuracy: 0.8751\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0963 - accuracy: 0.9746 - val_loss: 0.3247 - val_accuracy: 0.8746\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0899 - accuracy: 0.9772 - val_loss: 0.3288 - val_accuracy: 0.8748\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0838 - accuracy: 0.9800 - val_loss: 0.3359 - val_accuracy: 0.8723\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0787 - accuracy: 0.9815 - val_loss: 0.3402 - val_accuracy: 0.8730\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0733 - accuracy: 0.9834 - val_loss: 0.3493 - val_accuracy: 0.8715\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0691 - accuracy: 0.9844 - val_loss: 0.3514 - val_accuracy: 0.8737\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0638 - accuracy: 0.9866 - val_loss: 0.3591 - val_accuracy: 0.8734\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0601 - accuracy: 0.9881 - val_loss: 0.3663 - val_accuracy: 0.8701\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.0558 - accuracy: 0.9898 - val_loss: 0.3716 - val_accuracy: 0.8711\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.0524 - accuracy: 0.9905 - val_loss: 0.3777 - val_accuracy: 0.8711\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0483 - accuracy: 0.9923 - val_loss: 0.3847 - val_accuracy: 0.8702\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0453 - accuracy: 0.9928 - val_loss: 0.3919 - val_accuracy: 0.8706\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 2s 51ms/step - loss: 0.0421 - accuracy: 0.9940 - val_loss: 0.3997 - val_accuracy: 0.8704\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4353 - accuracy: 0.8516\n",
            "[0.43531104922294617, 0.851639986038208]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbUbnIMxrlr5"
      },
      "source": [
        "## BERT model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQCcK5Xk_GdM"
      },
      "source": [
        "### imports, get_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQv3v3aNrsj2",
        "outputId": "f106ddd0-5a1d-4c57-cc06-4fca5ce786a6"
      },
      "source": [
        "!pip3 install --quiet tensorflow\n",
        "!pip3 install --quiet tensorflow_text\n",
        "!pip install -q tf-models-official\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6MB 6.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849kB 6.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36.7MB 1.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 38.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 6.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 358kB 38.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 34.8MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8-UaCAtrsu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d510aa66-5ccf-40fb-c263-8f3cec6cce39"
      },
      "source": [
        "'''\n",
        "imports\n",
        "'''\n",
        "\n",
        "import os, sys, re, shutil\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.ops import string_ops\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optmizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print('GPU NAME:\\n\\t',tf.config.list_physical_devices('GPU'))\n",
        "'''\n",
        "train_data, test_data = tfds.load('imdb_reviews', split=[\"train\", \"test\"], \n",
        "                                  batch_size=-1, as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "'''\n",
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "# remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.10.0\n",
            "GPU is NOT AVAILABLE\n",
            "GPU NAME:\n",
            "\t []\n",
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMe6a9mSrs33"
      },
      "source": [
        "# create the train/validation split\n",
        "def get_datasets(batch=32, seed=42):\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "  batch_size = batch\n",
        "  seed = seed\n",
        "\n",
        "  raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "      'aclImdb/train',\n",
        "      batch_size=batch_size,\n",
        "      validation_split=0.2,\n",
        "      subset='training',\n",
        "      seed=seed)\n",
        "\n",
        "  class_names = raw_train_ds.class_names\n",
        "  train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "  val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "      'aclImdb/train',\n",
        "      batch_size=batch_size,\n",
        "      validation_split=0.2,\n",
        "      subset='validation',\n",
        "      seed=seed)\n",
        "\n",
        "  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "      'aclImdb/test',\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return train_ds, val_ds, test_ds\n",
        "\n",
        "# # example\n",
        "#\n",
        "# BS=32\n",
        "# train, validation, test = get_datasets(batch=BS)\n",
        "#"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNkgUcZXuST-"
      },
      "source": [
        "encoder_url = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "preprocessor_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYiXkUt2u7Ey"
      },
      "source": [
        "# tutorial test\n",
        "bert_preprocess_model = hub.KerasLayer(preprocessor_url)\n",
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sVAhWyAvjwd"
      },
      "source": [
        "# tutorial test\n",
        "bert_model = hub.KerasLayer(encoder_url)\n",
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {preprocessor_url}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfcvLt4y_ACa"
      },
      "source": [
        "### BERT model functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzvK3OKlv-75"
      },
      "source": [
        "# tutorial build the model\n",
        "def build_bert_model():\n",
        "  encoder_url = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "  preprocessor_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1'\n",
        "\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(preprocessor_url, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  # encoder same as bert_model\n",
        "  encoder = hub.KerasLayer(encoder_url, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOQyZAbuwUdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3c031d29-52e9-443f-8ab0-0a7beb688b99"
      },
      "source": [
        "def compile_bert_model(model,\n",
        "                       training_set,\n",
        "                       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                       metric=tf.metrics.BinaryAccuracy(),\n",
        "                       lr=3e-5,\n",
        "                       optim='adamw'):\n",
        "  loss = loss\n",
        "  # loss = tf.keras.losses.mean_squared_error(from_logits=True)\n",
        "  metrics = metric\n",
        "  init_lr = lr\n",
        "  epochs = 1\n",
        "\n",
        "\n",
        "  steps_per_epoch = tf.data.experimental.cardinality(training_set).numpy()\n",
        "  num_train_steps = steps_per_epoch * epochs\n",
        "  num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "\n",
        "  # optimizer = optimization.create_optimizer(\n",
        "  #     init_lr=init_lr,\n",
        "  #     num_train_steps=num_train_steps,\n",
        "  #     num_warmup_steps=num_warmup_steps,\n",
        "  #     optimizer_type='adamw'\n",
        "  # )\n",
        "  optim = optimization.create_optimizer(\n",
        "      init_lr=init_lr,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=int(num_train_steps*.13),\n",
        "      optimizer_type='adamw'\n",
        "  )\n",
        "  model.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
        "\n",
        "'''\n",
        "# example\n",
        "\n",
        "bertmodel = build_bert_model()\n",
        "compile_bert_model(model=bertmodel,training_set=train_ds)\n",
        "\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# example\\n\\nbertmodel = build_bert_model()\\ncompile_bert_model(model=bertmodel,training_set=train_ds)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RDoPVMbZZmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00d3e49-e0fc-4c34-f94c-923597258ad1"
      },
      "source": [
        "BATCH_SIZE=64\n",
        "train_ds, val_ds, test_ds = get_datasets(batch=BATCH_SIZE)\n",
        "cfm = build_bert_model()\n",
        "compile_bert_model(model=cfm,\n",
        "                   training_set=train_ds)\n",
        "\n",
        "text_test = tf.constant(['This movie was great, and I think that everyone should watch it! I am a massive fan of time travel comedies.',\n",
        "             'this was a very bad movie. I have never been a fan of Sherlock Holmes or Watson, but I thought I would give this kooky caper a try. What a mistake!!!'])\n",
        "labels_test = tf.constant([1.0, 0.0])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method CapturableResourceDeleter.__del__ of <tensorflow.python.training.tracking.tracking.CapturableResourceDeleter object at 0x7f2fe332f160>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py\", line 202, in __del__\n",
            "    self._destroy_resource()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\n",
            "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 237, in restored_function_body\n",
            "    return _call_concrete_function(function, inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 74, in _call_concrete_function\n",
            "    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\", line 106, in _call_flat\n",
            "    cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1938, in _call_flat\n",
            "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 579, in call\n",
            "    executor_type=executor_type)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\", line 1192, in partitioned_call\n",
            "    f.add_to_graph(graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 495, in add_to_graph\n",
            "    g._add_function(self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3345, in _add_function\n",
            "    gradient)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRHRBIhfxLIf"
      },
      "source": [
        "Train with  ```model.fit()``` on full Training Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59YHYFHCw2tF",
        "outputId": "2344ebb8-8341-4a8a-f3ef-be3d46e5d7ad"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  history = cfm.fit(x=train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=1)\n",
        "\n",
        "print(history.history)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 136s 433ms/step - loss: 0.4804 - binary_accuracy: 0.7487 - val_loss: 0.3862 - val_binary_accuracy: 0.8144\n",
            "{'loss': [0.48041561245918274], 'binary_accuracy': [0.7487499713897705], 'val_loss': [0.3862094581127167], 'val_binary_accuracy': [0.8144000172615051]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Y-9GTPxOEK"
      },
      "source": [
        "Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opIDCqoWcY4C",
        "outputId": "73ea4969-29b2-4f01-bc64-348ecec582ba"
      },
      "source": [
        "test_loss, test_acc = cfm.evaluate(test_ds)\n",
        "print(\"test loss = {}, test accuracy = {}\".format(test_loss,test_acc))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 67s 171ms/step - loss: 0.3821 - binary_accuracy: 0.8182\n",
            "test loss = 0.3820759057998657, test accuracy = 0.8182399868965149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9I4iZg2poEj",
        "outputId": "b2f0f873-fd47-41a5-a3eb-4eff27ad0f4b"
      },
      "source": [
        "history.history.keys()\n",
        "# print((history.history['binary_accuracy']))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYdhCsqFxPYR",
        "outputId": "56ee75c8-f8b4-4f30-c7ec-8b920b3b3d59"
      },
      "source": [
        "test_loss, test_accuracy = classifier_model.evaluate(test_ds)\n",
        "print(f'Loss: {test_loss}')\n",
        "print(f'Accuracy: {test_accuracy}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 70s 89ms/step - loss: 0.3607 - binary_accuracy: 0.8317\n",
            "Loss: 0.36073803901672363\n",
            "Accuracy: 0.8316799998283386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA5JfLV2jXgW"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ6VJNc18lEY"
      },
      "source": [
        "### setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTtP1QmMlRtg",
        "outputId": "231c1356-2ab1-49e1-a1dc-b1a04b1413c5"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BUFFER_SIZE = 1000 # vocabulary size?\n",
        "BATCH_SIZE = 32\n",
        "seed = 22\n",
        "\n",
        "train_ds, val_ds, test_ds = get_datasets(batch=BATCH_SIZE)\n",
        "# lstm_train_ds, lstm_val_ds, lstm_train_ds = get_datasets()\n",
        "\n",
        "text_test = tf.constant(['This movie was great, and I think that everyone should watch it! I am a massive fan of time travel comedies.',\n",
        "             'this was a very bad movie. I have never been a fan of Sherlock Holmes or Watson, but I thought I would give this kooky caper a try. What a mistake!!!'])\n",
        "labels_test = tf.constant([1.0, 0.0])\n",
        "\n",
        "VOCAB_SIZE=BUFFER_SIZE\n",
        "\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_ds.map(lambda text, label: text))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7QvM-v-8CZR"
      },
      "source": [
        "### step and train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6l_Ak6fuS8z"
      },
      "source": [
        "DEFAULT_STRIP_REGEX = r'[!\"#$%&()\\*\\+,-\\./:;<=>?@\\[\\\\\\]^_`{|}~\\']'\n",
        "'''\n",
        "def step(model, X):\n",
        "  # this function uses the LSTM to delete words from sentences\n",
        "  # \n",
        "  # for each word, the LSTM produces a policy as a bicategoriical distribution object\n",
        "  # use each word's policy to sample an action (0==keep, 1==delete)\n",
        "  # collect the summed log probabilities for each action to use as update weights\n",
        "  # \n",
        "  # return the outputs for each word in each sentence in the batch X\n",
        "  # return the actions for each sentence in the batch X\n",
        "  # return the summed log probabilities for each sentence in the batch X\n",
        "  batch_logits = model(X)\n",
        "  batch_actions =[[] for _ in batch_logits]\n",
        "  log_prob_sums =[None for _ in batch_logits]\n",
        "  new_X = []\n",
        "\n",
        "  for idx,sentence in enumerate(batch_logits):\n",
        "    temp_log_probs = []\n",
        "    start=time.time()\n",
        "    for probs in sentence:\n",
        "      # make a distribution for each word\n",
        "      pol = tfp.distributions.Categorical(probs=tf.nn.softmax(probs))\n",
        "      # sample from the distribution\n",
        "      act = pol.sample()\n",
        "      # save the action (0=keep,1=delete)\n",
        "      batch_actions[idx].append(act)\n",
        "      # with that action, get the log_prob\n",
        "      log_prob = pol.log_prob(act)\n",
        "      # save that log_prob to a list \n",
        "      temp_log_probs.append(log_prob)\n",
        "    # if idx==0: print(\"\\tpolicy, action sampling, and log_prob time : \",time.time()-start)\n",
        "    # sum the log probs for this sentence and add to list\n",
        "    log_prob_sums[idx] = sum(temp_log_probs)\n",
        "\n",
        "    x = str(X[idx].numpy(),'utf-8')\n",
        "    acts = batch_actions[idx]\n",
        "    \n",
        "    tmp_str = string_ops.regex_replace(x,DEFAULT_STRIP_REGEX,'')\n",
        "    tmp_str = str(tmp_str.numpy(), 'utf-8').strip()\n",
        "    tmp_list = [i for i in tmp_str.split(' ') if i]\n",
        "\n",
        "    if (len(tmp_list) > len(acts)):\n",
        "      print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      sys.exit()\n",
        "      # _templist = [i for i in tmp_str.split(' ') if i]\n",
        "      # if len(acts) != len(_templist):\n",
        "      #   print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      #   print('_templist len : ',len(_templist))\n",
        "      #   print(_templist)\n",
        "      #   print('acts len : ', len(acts))\n",
        "      #   sys.exit()\n",
        "      # # print('{} ERROR: more tokens than actions...'.format(idx))\n",
        "    new_list = []\n",
        "    for i,toke in enumerate(tmp_list):\n",
        "      if acts[i] != 1:\n",
        "        new_list.append(toke)\n",
        "    new_X.append(' '.join(new_list))\n",
        "    if idx==0: print(\"\\tsentence action and word-removal time : \",time.time()-start)\n",
        "\n",
        "  return batch_logits, new_X, log_prob_sums\n",
        "'''\n",
        "\n",
        "\n",
        "def step2(model, X):\n",
        "  batch_logits = model(X)\n",
        "  batch_actions =[[] for _ in batch_logits]\n",
        "  log_prob_sums =[0.0 for _ in batch_logits]\n",
        "  _log_prob_sums =[None for _ in batch_logits]\n",
        "  new_X = []\n",
        "\n",
        "  for idx,sentence in enumerate(batch_logits):\n",
        "    temp_log_probs = []\n",
        "    start=time.time()\n",
        "\n",
        "    pol = tfp.distributions.Bernoulli(logits=sentence)\n",
        "    act = pol.sample()\n",
        "    batch_actions[idx] = [ac for ac in act]\n",
        "    log_probs = [pol.log_prob(ac) for ac in act]\n",
        "    lpkeep = pol.log_prob([0])\n",
        "    lpdel = pol.log_prob([1])\n",
        "\n",
        "    onect=0\n",
        "    zeroct=0\n",
        "    lp_list = []\n",
        "    for i,ac in enumerate(act):\n",
        "      if int(ac) == 1:\n",
        "        lp_list.append(lpdel[i])\n",
        "        onect+=1\n",
        "      else:\n",
        "        lp_list.append(lpkeep[i])\n",
        "        zeroct+=1\n",
        "    # print(onect,\"/\",zeroct)\n",
        "    log_prob_sums[idx] = sum(lp_list)\n",
        "    x = str(X[idx].numpy(),'utf-8')\n",
        "    acts = batch_actions[idx]\n",
        "    tmp_str = string_ops.regex_replace(x,DEFAULT_STRIP_REGEX,'')\n",
        "    tmp_str = str(tmp_str.numpy(), 'utf-8').strip()\n",
        "    tmp_list = [i for i in tmp_str.split(' ') if i]\n",
        "    if (len(tmp_list) > len(acts)):\n",
        "      print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      sys.exit()\n",
        "    new_list = []\n",
        "    addct=0\n",
        "    for i,toke in enumerate(tmp_list):\n",
        "      if acts[i] != 1:\n",
        "        new_list.append(toke)\n",
        "    new_X.append(' '.join(new_list))\n",
        "    if idx==0: \n",
        "      print(\"\\tsentence action and word-removal time : \",time.time()-start)\n",
        "      # print(X[0])\n",
        "      # print(new_X[0])\n",
        "  return batch_logits, new_X, log_prob_sums\n",
        "\n",
        "\n",
        "def remove_words(lstm, X):\n",
        "  batch_logits = lstm(X)\n",
        "  batch_actions =[[] for _ in batch_logits]\n",
        "  new_X = []\n",
        "  stats=[]\n",
        "  for idx,sentence in enumerate(batch_logits):\n",
        "    start=time.time()\n",
        "    temp_stats = {'num_words':len(sentence),'num_deleted':0}\n",
        "    pol = tfp.distributions.Bernoulli(logits=sentence)\n",
        "    act = pol.sample()\n",
        "    batch_actions[idx] = [ac for ac in act]\n",
        "\n",
        "    x = str(X[idx].numpy(),'utf-8')\n",
        "    acts = batch_actions[idx]\n",
        "    tmp_str = string_ops.regex_replace(x,DEFAULT_STRIP_REGEX,'')\n",
        "    tmp_str = str(tmp_str.numpy(), 'utf-8').strip()\n",
        "    tmp_list = [i for i in tmp_str.split(' ') if i]\n",
        "    if (len(tmp_list) > len(acts)):\n",
        "      print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      sys.exit()\n",
        "    new_list = []\n",
        "    addct=0\n",
        "    for i,toke in enumerate(tmp_list):\n",
        "      if acts[i] != 1:\n",
        "        new_list.append(toke)\n",
        "      else:\n",
        "        temp_stats['num_deleted'] +=1\n",
        "    stats.append(temp_stats)\n",
        "    new_X.append(' '.join(new_list))\n",
        "  return new_X, stats\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1AjHewEc9id"
      },
      "source": [
        "# from tensorflow.compat.v1.distributions import Multinomial as multinomial\n",
        "'''\n",
        "tf.random.categorical(logits=np.array([[.1,.2,.9]]),num_samples=1)\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import time\n",
        "# \n",
        "# policy gradient (REINFORCE) training loop with LSTM model and BERT sentiment classifier\n",
        "# classifier must be compiled!\n",
        "# \n",
        "def train_vpg(lstm, optimizer, classifier, training_set, validation_set, epochs=5):\n",
        "  total_start=time.time()\n",
        "  stepct=0\n",
        "  # with tf.device('/device:GPU:0'):\n",
        "  for e in range(epochs):\n",
        "    epoch_losses=[]\n",
        "    counter=0\n",
        "    trainlen = len(training_set)\n",
        "    for idx,ex_lab in enumerate(training_set):\n",
        "    # for idx,ex_lab in enumerate(training_set.take(100)):\n",
        "      starttime=time.time()\n",
        "      example, label = ex_lab[0], ex_lab[1]\n",
        "      counter+=1\n",
        "      print('epoch={}\\tbatch={}'.format(e,counter))\n",
        "      stepct+=1\n",
        "      # run through the lstm\n",
        "      logits, new_example, logprob_sums = None, None, None\n",
        "      with tf.GradientTape() as t:\n",
        "        start = time.time()\n",
        "        # logits, new_example, logprob_sums = step(lstm, example)\n",
        "        logits, new_example, logprob_sums = step2(lstm, example)\n",
        "        # logging for curiosity\n",
        "        if e==0 and idx==0:\n",
        "          print('step time for one batch: {:.4f}'.format(time.time()-start))\n",
        "\n",
        "        # get BERT evaluations on these\n",
        "        start=time.time()\n",
        "        new_outs = classifier(tf.constant(new_example))\n",
        "        # get bert evaluation on full sentences\n",
        "        baseline_outs = classifier(example)\n",
        "\n",
        "        if e==0 and idx==0:\n",
        "          print('BERT processing time for one batch : {:.4f}'.format(time.time()-start))\n",
        "\n",
        "        # reward LSTM with the improvement over the original sentences\n",
        "        baseline_loss = tf.keras.losses.mean_squared_error(baseline_outs,tf.cast(label,float))\n",
        "        loss_object = tf.keras.losses.mean_squared_error(new_outs,tf.cast(label,float))\n",
        "        # loss_object = tf.keras.losses.binary_crossentropy(new_outs,tf.cast(label,float))\n",
        "        adjusted_loss = loss_object-baseline_loss\n",
        "        # print(\"loss_x' - loss_base : \",np.array(adjusted_loss))\n",
        "        epoch_losses.append(adjusted_loss.numpy())\n",
        "\n",
        "        # use BERT's loss for update:\n",
        "        # use the negative losses to weight the log_probs\n",
        "        weighted_logprobs = -(adjusted_loss)*logprob_sums\n",
        "        # end with tf.GradientTape()\n",
        "\n",
        "      # train bert by fitting on new_examples\n",
        "      # this way, BERT and the LSTM train together\n",
        "      with tf.device('/device:GPU:0'):\n",
        "        history = classifier.fit(x=tf.constant(new_example),\n",
        "                                  y=label,\n",
        "                                  validation_split=.2,\n",
        "                                  batch_size=len(new_example),\n",
        "                                  epochs=2,\n",
        "                                  verbose=1)\n",
        "      # print(\"BERT training accuracy : \", np.mean(history.history['binary_accuracy']))\n",
        "\n",
        "      # get gradients and apply update\n",
        "      gradients = t.gradient(weighted_logprobs, lstm.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients,lstm.trainable_variables))\n",
        "      if idx == 1: print('batch time {:.2f}'.format(time.time()-starttime))\n",
        "      # end for\n",
        "    print('\\n_____________________________')\n",
        "    print('[{}]\\t avg training loss : {}'.format(e,np.mean(epoch_losses)))\n",
        "    # print('[{}]\\t total train inloss : {}'.format(e,np.sum(epoch_losses)))\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      val_loss, val_acc = classifier.evaluate(validation_set)\n",
        "    print(\"[{}] BERT validation loss     :\\t{}\\n\\t\\tvalidation accuracy :\\t{}\".format(idx,val_loss, val_acc))\n",
        "\n",
        "    '''\n",
        "    # validate \n",
        "    validate()\n",
        "    '''\n",
        "\n",
        "    # end for\n",
        "  print('DONE. {:.4f}'.format(time.time()-total_start))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCZ45NO0XrOL"
      },
      "source": [
        "\n",
        "def evaluate_lstm_model(lstm, classifier, testing_set):\n",
        "  test_x=[]\n",
        "  test_y=[]\n",
        "  total=len(testing_set)\n",
        "  stats = []\n",
        "  for idx,example in enumerate(testing_set):\n",
        "    test_y.append(example[1].numpy())\n",
        "    new_x, _stats = remove_words(lstm_model,example[0])\n",
        "    stats.append(_stats) \n",
        "    test_x.append(np.array(new_x))\n",
        "    print('LSTM processing batch',idx,'/',total)\n",
        "  test_loss, test_acc = classifier.evaluate(x=test_x,y=test_y)\n",
        "  return test_loss, test_acc, stats\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7EwxU0DdEhj"
      },
      "source": [
        "### model setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax1VDY1H67yw"
      },
      "source": [
        "# instantiate the BERT model and classify on two sentences\n",
        "classifier_model = build_bert_model()\n",
        "compile_bert_model(model=classifier_model,\n",
        "                   training_set=train_ds)\n",
        "# with tf.device('/device:GPU:0'):\n",
        "#   history = classifier_model.fit(x=text_test, y=labels_test, batch_size=1, epochs=2)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZpTYcQ638M"
      },
      "source": [
        "# instantiate LSTM \n",
        "lstm_model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation=None)\n",
        "])\n",
        "\n",
        "lstm_optim = tf.optimizers.Adam()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3cDUrEi8GCe"
      },
      "source": [
        "### train_lstm_vpg "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hnQ-8izxDDG"
      },
      "source": [
        "training on a subset of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDWXUsqo85jY",
        "outputId": "534ad028-9af6-4720-df40-4378f5a45ff5"
      },
      "source": [
        "train_vpg(lstm_model, lstm_optim, classifier_model, train_ds.shard(10,0), val_ds.shard(10,0), epochs=1)\n",
        "test_loss, test_accuracy = classifier_model.evaluate(test_ds)\n",
        "print(f'Loss: {test_loss}')\n",
        "print(f'Accuracy: {test_accuracy}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0\tbatch=1\n",
            "\tsentence action and word-removal time :  0.4469716548919678\n",
            "step time for one batch: 18.4888\n",
            "BERT processing time for one batch : 8.4466\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8883 - binary_accuracy: 0.3860 - val_loss: 0.9248 - val_binary_accuracy: 0.1429\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.8753 - binary_accuracy: 0.4000 - val_loss: 0.9220 - val_binary_accuracy: 0.1429\n",
            "epoch=0\tbatch=2\n",
            "\tsentence action and word-removal time :  0.6930127143859863\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 0.7506 - binary_accuracy: 0.4000 - val_loss: 0.8698 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.7502 - binary_accuracy: 0.4400 - val_loss: 0.8583 - val_binary_accuracy: 0.4286\n",
            "batch time 61.16\n",
            "epoch=0\tbatch=3\n",
            "\tsentence action and word-removal time :  0.4455559253692627\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.7331 - binary_accuracy: 0.4400 - val_loss: 0.6068 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.7722 - binary_accuracy: 0.5200 - val_loss: 0.6248 - val_binary_accuracy: 0.1429\n",
            "epoch=0\tbatch=4\n",
            "\tsentence action and word-removal time :  0.351729154586792\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 0.8207 - binary_accuracy: 0.5200 - val_loss: 0.7069 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 0.7733 - binary_accuracy: 0.4400 - val_loss: 0.7131 - val_binary_accuracy: 0.1429\n",
            "epoch=0\tbatch=5\n",
            "\tsentence action and word-removal time :  0.6667811870574951\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 0.8057 - binary_accuracy: 0.5200 - val_loss: 0.6799 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.7861 - binary_accuracy: 0.4400 - val_loss: 0.6738 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=6\n",
            "\tsentence action and word-removal time :  0.27399206161499023\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.7085 - binary_accuracy: 0.4800 - val_loss: 0.6192 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.7046 - binary_accuracy: 0.4000 - val_loss: 0.6070 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=7\n",
            "\tsentence action and word-removal time :  0.42376041412353516\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 538ms/step - loss: 0.7449 - binary_accuracy: 0.4800 - val_loss: 0.7533 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.7462 - binary_accuracy: 0.5200 - val_loss: 0.7619 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=8\n",
            "\tsentence action and word-removal time :  0.43769383430480957\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 541ms/step - loss: 0.7819 - binary_accuracy: 0.2400 - val_loss: 0.6940 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 538ms/step - loss: 0.7461 - binary_accuracy: 0.3200 - val_loss: 0.6867 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=9\n",
            "\tsentence action and word-removal time :  0.6553859710693359\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 0.6261 - binary_accuracy: 0.4800 - val_loss: 0.6126 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.7028 - binary_accuracy: 0.4800 - val_loss: 0.6129 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=10\n",
            "\tsentence action and word-removal time :  0.46146225929260254\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 0.7235 - binary_accuracy: 0.3600 - val_loss: 0.7498 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.6769 - binary_accuracy: 0.3200 - val_loss: 0.7382 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=11\n",
            "\tsentence action and word-removal time :  0.37424588203430176\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 0.6788 - binary_accuracy: 0.4800 - val_loss: 0.7913 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.6647 - binary_accuracy: 0.5200 - val_loss: 0.7832 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=12\n",
            "\tsentence action and word-removal time :  0.6202878952026367\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.7112 - binary_accuracy: 0.4800 - val_loss: 0.6402 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.7419 - binary_accuracy: 0.4800 - val_loss: 0.6652 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=13\n",
            "\tsentence action and word-removal time :  0.658367395401001\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.6992 - binary_accuracy: 0.4800 - val_loss: 0.6621 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.6554 - binary_accuracy: 0.6000 - val_loss: 0.6515 - val_binary_accuracy: 0.2857\n",
            "epoch=0\tbatch=14\n",
            "\tsentence action and word-removal time :  0.5991878509521484\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 0.7271 - binary_accuracy: 0.4800 - val_loss: 0.7896 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.6893 - binary_accuracy: 0.5600 - val_loss: 0.7998 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=15\n",
            "\tsentence action and word-removal time :  0.44761157035827637\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 0.6605 - binary_accuracy: 0.7200 - val_loss: 0.8112 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6586 - binary_accuracy: 0.7600 - val_loss: 0.8004 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=16\n",
            "\tsentence action and word-removal time :  0.9100782871246338\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.6404 - binary_accuracy: 0.5600 - val_loss: 0.7058 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.6428 - binary_accuracy: 0.5600 - val_loss: 0.7066 - val_binary_accuracy: 0.2857\n",
            "epoch=0\tbatch=17\n",
            "\tsentence action and word-removal time :  0.33231019973754883\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 0.6838 - binary_accuracy: 0.6000 - val_loss: 0.6589 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.6566 - binary_accuracy: 0.6400 - val_loss: 0.6649 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=18\n",
            "\tsentence action and word-removal time :  0.37825584411621094\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.6948 - binary_accuracy: 0.4800 - val_loss: 0.5668 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.6336 - binary_accuracy: 0.6400 - val_loss: 0.5625 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=19\n",
            "\tsentence action and word-removal time :  0.6492753028869629\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.6629 - binary_accuracy: 0.4800 - val_loss: 0.7009 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 0.6269 - binary_accuracy: 0.5200 - val_loss: 0.7063 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=20\n",
            "\tsentence action and word-removal time :  0.32976365089416504\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 0.6868 - binary_accuracy: 0.4000 - val_loss: 0.6128 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.7116 - binary_accuracy: 0.4400 - val_loss: 0.6149 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=21\n",
            "\tsentence action and word-removal time :  0.3676927089691162\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 0.7025 - binary_accuracy: 0.4000 - val_loss: 0.6513 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.6912 - binary_accuracy: 0.4800 - val_loss: 0.6678 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=22\n",
            "\tsentence action and word-removal time :  0.5155718326568604\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 542ms/step - loss: 0.7276 - binary_accuracy: 0.6400 - val_loss: 0.5984 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6996 - binary_accuracy: 0.6000 - val_loss: 0.5853 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=23\n",
            "\tsentence action and word-removal time :  0.3614025115966797\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 0.6762 - binary_accuracy: 0.5600 - val_loss: 0.5984 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6333 - binary_accuracy: 0.6000 - val_loss: 0.6077 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=24\n",
            "\tsentence action and word-removal time :  1.2675292491912842\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 0.5532 - binary_accuracy: 0.7600 - val_loss: 0.7656 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.5385 - binary_accuracy: 0.7600 - val_loss: 0.7747 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=25\n",
            "\tsentence action and word-removal time :  0.3484175205230713\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 0.7324 - binary_accuracy: 0.7600 - val_loss: 0.7358 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.6745 - binary_accuracy: 0.7600 - val_loss: 0.7122 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=26\n",
            "\tsentence action and word-removal time :  0.4842829704284668\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 0.7719 - binary_accuracy: 0.6000 - val_loss: 0.7330 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.6786 - binary_accuracy: 0.7200 - val_loss: 0.6803 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=27\n",
            "\tsentence action and word-removal time :  0.6189389228820801\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 542ms/step - loss: 0.6214 - binary_accuracy: 0.7200 - val_loss: 0.5329 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.5836 - binary_accuracy: 0.6000 - val_loss: 0.4746 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=28\n",
            "\tsentence action and word-removal time :  0.32712841033935547\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 0.7657 - binary_accuracy: 0.5200 - val_loss: 0.4618 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.7325 - binary_accuracy: 0.4800 - val_loss: 0.4567 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=29\n",
            "\tsentence action and word-removal time :  0.6399025917053223\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.5814 - binary_accuracy: 0.6400 - val_loss: 0.4680 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 512ms/step - loss: 0.5688 - binary_accuracy: 0.6400 - val_loss: 0.4582 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=30\n",
            "\tsentence action and word-removal time :  0.6484062671661377\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 551ms/step - loss: 0.9170 - binary_accuracy: 0.3600 - val_loss: 0.7070 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.8214 - binary_accuracy: 0.4400 - val_loss: 0.6207 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=31\n",
            "\tsentence action and word-removal time :  0.37224817276000977\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.5950 - binary_accuracy: 0.6000 - val_loss: 0.5694 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.6318 - binary_accuracy: 0.6400 - val_loss: 0.6533 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=32\n",
            "\tsentence action and word-removal time :  0.49341654777526855\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.6503 - binary_accuracy: 0.5200 - val_loss: 0.7105 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.7123 - binary_accuracy: 0.6000 - val_loss: 0.7536 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=33\n",
            "\tsentence action and word-removal time :  0.6577041149139404\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 0.5756 - binary_accuracy: 0.7600 - val_loss: 0.8629 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6255 - binary_accuracy: 0.6400 - val_loss: 0.9261 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=34\n",
            "\tsentence action and word-removal time :  0.4424295425415039\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 536ms/step - loss: 0.6557 - binary_accuracy: 0.6400 - val_loss: 0.7721 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.6532 - binary_accuracy: 0.7200 - val_loss: 0.7572 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=35\n",
            "\tsentence action and word-removal time :  0.30635809898376465\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.7470 - binary_accuracy: 0.6000 - val_loss: 0.6520 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6780 - binary_accuracy: 0.6000 - val_loss: 0.6589 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=36\n",
            "\tsentence action and word-removal time :  0.5772931575775146\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 0.5817 - binary_accuracy: 0.6800 - val_loss: 0.6590 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 0.6401 - binary_accuracy: 0.6400 - val_loss: 0.6247 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=37\n",
            "\tsentence action and word-removal time :  0.3632543087005615\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 547ms/step - loss: 0.7113 - binary_accuracy: 0.6000 - val_loss: 0.4646 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 512ms/step - loss: 0.6286 - binary_accuracy: 0.6400 - val_loss: 0.4432 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=38\n",
            "\tsentence action and word-removal time :  0.4220707416534424\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 547ms/step - loss: 0.4899 - binary_accuracy: 0.8400 - val_loss: 0.7095 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.4630 - binary_accuracy: 0.8400 - val_loss: 0.7988 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=39\n",
            "\tsentence action and word-removal time :  0.5802414417266846\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.6796 - binary_accuracy: 0.5600 - val_loss: 0.9434 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.7441 - binary_accuracy: 0.5200 - val_loss: 0.9262 - val_binary_accuracy: 0.2857\n",
            "epoch=0\tbatch=40\n",
            "\tsentence action and word-removal time :  0.6520888805389404\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 0.5662 - binary_accuracy: 0.6000 - val_loss: 0.7419 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.5733 - binary_accuracy: 0.5600 - val_loss: 0.6526 - val_binary_accuracy: 0.2857\n",
            "epoch=0\tbatch=41\n",
            "\tsentence action and word-removal time :  0.3542900085449219\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 0.5835 - binary_accuracy: 0.6000 - val_loss: 0.6958 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.5529 - binary_accuracy: 0.6000 - val_loss: 0.7231 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=42\n",
            "\tsentence action and word-removal time :  0.3422670364379883\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 569ms/step - loss: 0.6472 - binary_accuracy: 0.5600 - val_loss: 0.5516 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.6147 - binary_accuracy: 0.6000 - val_loss: 0.6295 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=43\n",
            "\tsentence action and word-removal time :  1.0996007919311523\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.5328 - binary_accuracy: 0.7200 - val_loss: 0.5388 - val_binary_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.6119 - binary_accuracy: 0.6400 - val_loss: 0.5951 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=44\n",
            "\tsentence action and word-removal time :  0.5071403980255127\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 542ms/step - loss: 0.6819 - binary_accuracy: 0.6400 - val_loss: 0.5970 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 0.7047 - binary_accuracy: 0.6400 - val_loss: 0.5958 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=45\n",
            "\tsentence action and word-removal time :  0.6528306007385254\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.7032 - binary_accuracy: 0.6000 - val_loss: 0.6106 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.6268 - binary_accuracy: 0.8000 - val_loss: 0.5203 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=46\n",
            "\tsentence action and word-removal time :  0.6601889133453369\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 0.6012 - binary_accuracy: 0.5600 - val_loss: 0.5870 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.6204 - binary_accuracy: 0.4000 - val_loss: 0.6169 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=47\n",
            "\tsentence action and word-removal time :  0.6683497428894043\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 0.6884 - binary_accuracy: 0.5600 - val_loss: 0.6927 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.6881 - binary_accuracy: 0.5200 - val_loss: 0.6697 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=48\n",
            "\tsentence action and word-removal time :  0.428987979888916\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 566ms/step - loss: 0.4620 - binary_accuracy: 0.8800 - val_loss: 0.5904 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.4925 - binary_accuracy: 0.7600 - val_loss: 0.5818 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=49\n",
            "\tsentence action and word-removal time :  0.41292881965637207\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.5485 - binary_accuracy: 0.8000 - val_loss: 0.6049 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.5394 - binary_accuracy: 0.7600 - val_loss: 0.5756 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=50\n",
            "\tsentence action and word-removal time :  0.29210948944091797\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 0.5386 - binary_accuracy: 0.7200 - val_loss: 0.7611 - val_binary_accuracy: 0.2857\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.5675 - binary_accuracy: 0.6800 - val_loss: 0.7740 - val_binary_accuracy: 0.2857\n",
            "epoch=0\tbatch=51\n",
            "\tsentence action and word-removal time :  0.49079275131225586\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 0.5880 - binary_accuracy: 0.6000 - val_loss: 0.6807 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.5339 - binary_accuracy: 0.6400 - val_loss: 0.6724 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=52\n",
            "\tsentence action and word-removal time :  0.2761344909667969\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 0.6391 - binary_accuracy: 0.6000 - val_loss: 0.6109 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6177 - binary_accuracy: 0.5600 - val_loss: 0.5946 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=53\n",
            "\tsentence action and word-removal time :  1.101292610168457\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 0.5885 - binary_accuracy: 0.6800 - val_loss: 0.5365 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 555ms/step - loss: 0.5291 - binary_accuracy: 0.6000 - val_loss: 0.5130 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=54\n",
            "\tsentence action and word-removal time :  0.6335179805755615\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 0.5757 - binary_accuracy: 0.7200 - val_loss: 0.5880 - val_binary_accuracy: 0.5714\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 0.5658 - binary_accuracy: 0.8000 - val_loss: 0.5752 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=55\n",
            "\tsentence action and word-removal time :  0.6675643920898438\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 545ms/step - loss: 0.7526 - binary_accuracy: 0.6400 - val_loss: 0.6328 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6624 - binary_accuracy: 0.7200 - val_loss: 0.6000 - val_binary_accuracy: 0.5714\n",
            "epoch=0\tbatch=56\n",
            "\tsentence action and word-removal time :  1.117241621017456\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.5024 - binary_accuracy: 0.7200 - val_loss: 0.5636 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.4950 - binary_accuracy: 0.6800 - val_loss: 0.5883 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=57\n",
            "\tsentence action and word-removal time :  0.6185193061828613\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.6021 - binary_accuracy: 0.5600 - val_loss: 0.4843 - val_binary_accuracy: 0.4286\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.5415 - binary_accuracy: 0.8000 - val_loss: 0.4602 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=58\n",
            "\tsentence action and word-removal time :  0.5030956268310547\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 542ms/step - loss: 0.5426 - binary_accuracy: 0.6800 - val_loss: 0.7208 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 0.5762 - binary_accuracy: 0.6800 - val_loss: 0.7930 - val_binary_accuracy: 0.4286\n",
            "epoch=0\tbatch=59\n",
            "\tsentence action and word-removal time :  0.466982364654541\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 0.6186 - binary_accuracy: 0.6800 - val_loss: 0.4063 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.5380 - binary_accuracy: 0.8000 - val_loss: 0.4045 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=60\n",
            "\tsentence action and word-removal time :  0.3964684009552002\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 559ms/step - loss: 0.6222 - binary_accuracy: 0.5600 - val_loss: 0.6471 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.5975 - binary_accuracy: 0.6000 - val_loss: 0.7074 - val_binary_accuracy: 0.7143\n",
            "epoch=0\tbatch=61\n",
            "\tsentence action and word-removal time :  0.48585009574890137\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 549ms/step - loss: 0.4919 - binary_accuracy: 0.7600 - val_loss: 0.3461 - val_binary_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.5049 - binary_accuracy: 0.8400 - val_loss: 0.3189 - val_binary_accuracy: 1.0000\n",
            "epoch=0\tbatch=62\n",
            "\tsentence action and word-removal time :  0.3799159526824951\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.4530 - binary_accuracy: 0.7200 - val_loss: 0.4231 - val_binary_accuracy: 0.8571\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.4524 - binary_accuracy: 0.8000 - val_loss: 0.4270 - val_binary_accuracy: 0.8571\n",
            "epoch=0\tbatch=63\n",
            "\tsentence action and word-removal time :  0.6354334354400635\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 0.7411 - binary_accuracy: 0.5600 - val_loss: 0.3873 - val_binary_accuracy: 0.7143\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.7000 - binary_accuracy: 0.6800 - val_loss: 0.3978 - val_binary_accuracy: 0.7143\n",
            "\n",
            "_____________________________\n",
            "[0]\t avg training loss : -0.22936977446079254\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.5161 - binary_accuracy: 0.6816\n",
            "[62] BERT validation loss     :\t0.5160757899284363\n",
            "\t\tvalidation accuracy :\t0.681640625\n",
            "DONE. 3440.7592\n",
            "248/782 [========>.....................] - ETA: 19:41 - loss: 0.5204 - binary_accuracy: 0.6972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-072ea0796a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_vpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {test_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {test_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WGsL0fTEJh6"
      },
      "source": [
        "evaluate on a shard of testing set\n",
        "\n",
        "*   LSTM removes words from batches\n",
        "*   evaluate BERT on the pruned sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu1ofsx9psLL",
        "outputId": "49655d01-71a2-4e66-f63c-698c5577ca71"
      },
      "source": [
        "# evaluate the full classifier model on the validation set\n",
        "test_loss, test_accuracy, stats = evaluate_lstm_model(lstm_model, classifier_model, test_ds.shard(50,1))\n",
        "print(f'Loss: {test_loss}')\n",
        "print(f'Accuracy: {test_accuracy}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM processing batch 0 / 16\n",
            "LSTM processing batch 1 / 16\n",
            "LSTM processing batch 2 / 16\n",
            "LSTM processing batch 3 / 16\n",
            "LSTM processing batch 4 / 16\n",
            "LSTM processing batch 5 / 16\n",
            "LSTM processing batch 6 / 16\n",
            "LSTM processing batch 7 / 16\n",
            "LSTM processing batch 8 / 16\n",
            "LSTM processing batch 9 / 16\n",
            "LSTM processing batch 10 / 16\n",
            "LSTM processing batch 11 / 16\n",
            "LSTM processing batch 12 / 16\n",
            "LSTM processing batch 13 / 16\n",
            "LSTM processing batch 14 / 16\n",
            "LSTM processing batch 15 / 16\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5304 - binary_accuracy: 0.7500\n",
            "Loss: 0.5303962230682373\n",
            "Accuracy: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omN-vujCD_sT"
      },
      "source": [
        "evaluate on a shard of test set without removing words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1msO8hd-6e63",
        "outputId": "f250b3de-f2ff-4e5c-8aed-f0a991943e96"
      },
      "source": [
        "test_loss, test_accuracy = classifier_model.evaluate(test_ds.shard(50,1))\n",
        "print(f'Loss: {test_loss}')\n",
        "print(f'Accuracy: {test_accuracy}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 33s 2s/step - loss: 0.5054 - binary_accuracy: 0.7266\n",
            "Loss: 0.5053861737251282\n",
            "Accuracy: 0.7265625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR54Z5tCEB0Q"
      },
      "source": [
        "evaluate on a "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ntb6wn_D7OI"
      },
      "source": [
        "average words deleted per review?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdHc8J8LCu4i",
        "outputId": "b80a3e06-bdfa-4950-f6bd-b497a9284d67"
      },
      "source": [
        "# print(np.mean(stats[:]['num_deleted']))\n",
        "# print(([s for s in stats[:][:]]))\n",
        "mn = 0\n",
        "sents=0\n",
        "for batch in stats:\n",
        "  for sentDict in batch:\n",
        "    sents+=1\n",
        "    mn+=sentDict['num_deleted']\n",
        "print('avg deletions:',mn/sents)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg deletions: 111.28125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uPcfpU8Ko15"
      },
      "source": [
        "# MLP (incomplete)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJcpaGlUKn_s"
      },
      "source": [
        "# alternative to LSTM\n",
        "# every word is an individual training example\n",
        "# \n",
        "# striclty worse than LSTM\n",
        "mlp_model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        mask_zero=False),\n",
        "    tf.keras.layers.Dense(64, activation='tanh'),\n",
        "    tf.keras.layers.Dense(1,activation=None)\n",
        "])\n",
        "\n",
        "def mlp_step(model, X):\n",
        "  batch_logits=[]\n",
        "  for x in X:\n",
        "    string = str(x.numpy(),'utf-8').strip()\n",
        "    string = string_ops.regex_replace(string,DEFAULT_STRIP_REGEX,'')\n",
        "    string_input = [s for s in string.split(' ') if s]\n",
        "    batch_logits.append(model(string_input))\n",
        "\n",
        "  batch_actions =[[] for _ in batch_logits]\n",
        "  log_prob_sums =[None for _ in batch_logits]\n",
        "  new_X = []\n",
        "\n",
        "  for idx,sentence in enumerate(batch_logits):\n",
        "    temp_log_probs = []\n",
        "    start=time.time()\n",
        "    for probs in sentence:\n",
        "      # make a distribution for each word\n",
        "      pol = tfp.distributions.Categorical(probs=tf.nn.softmax(probs))\n",
        "      # sample from the distribution\n",
        "      act = pol.sample()\n",
        "      # save the action (0=keep,1=delete)\n",
        "      batch_actions[idx].append(act)\n",
        "      # with that action, get the log_prob\n",
        "      log_prob = pol.log_prob(act)\n",
        "      # save that log_prob to a list \n",
        "      temp_log_probs.append(log_prob)\n",
        "    log_prob_sums[idx] = sum(temp_log_probs)\n",
        "\n",
        "    x = str(X[idx].numpy(),'utf-8')\n",
        "    acts = batch_actions[idx]\n",
        "    \n",
        "    tmp_str = string_ops.regex_replace(x,DEFAULT_STRIP_REGEX,'')\n",
        "    tmp_str = str(tmp_str.numpy(), 'utf-8').strip()\n",
        "    tmp_list = [i for i in tmp_str.split(' ') if i]\n",
        "    start=time.time()\n",
        "    if (len(tmp_list) > len(acts)):\n",
        "      print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      sys.exit()\n",
        "    new_list = []\n",
        "    for i,toke in enumerate(tmp_list):\n",
        "      if acts[i] != 1:\n",
        "        new_list.append(toke)\n",
        "    new_X.append(' '.join(new_list))\n",
        "\n",
        "  return batch_logits, new_X, log_prob_sums\n",
        "\n",
        "def mlpstep2(model, X):\n",
        "  minibatch=[]\n",
        "  for idx,x in enumerate(X):\n",
        "    string = str(x.numpy(),'utf-8').strip()\n",
        "    string = string_ops.regex_replace(string,DEFAULT_STRIP_REGEX,'')\n",
        "    string_input = [s for s in string.split(' ') if s]\n",
        "    minibatch.append(model(string_input))\n",
        "    # minibatch is split strins\n",
        "    print(minibatch[idx])\n",
        "    sys.exit()\n",
        "\n",
        "  batch_actions =[[] for _ in batch_logits]\n",
        "  log_prob_sums =[0.0 for _ in batch_logits]\n",
        "  _log_prob_sums =[None for _ in batch_logits]\n",
        "  new_X = []\n",
        "\n",
        "  for idx,sentence in enumerate(batch_logits):\n",
        "    temp_log_probs = []\n",
        "    start=time.time()\n",
        "\n",
        "    pol = tfp.distributions.Bernoulli(logits=sentence)\n",
        "    act = pol.sample()\n",
        "    batch_actions[idx] = [ac for ac in act]\n",
        "    log_probs = [pol.log_prob(ac) for ac in act]\n",
        "    lpkeep = pol.log_prob([0])\n",
        "    lpdel = pol.log_prob([1])\n",
        "\n",
        "    onect=0\n",
        "    zeroct=0\n",
        "    lp_list = []\n",
        "    for i,ac in enumerate(act):\n",
        "      if int(ac) == 1:\n",
        "        lp_list.append(lpdel[i])\n",
        "        onect+=1\n",
        "      else:\n",
        "        lp_list.append(lpkeep[i])\n",
        "        zeroct+=1\n",
        "    # print(onect,\"/\",zeroct)\n",
        "    log_prob_sums[idx] = sum(lp_list)\n",
        "    x = str(X[idx].numpy(),'utf-8')\n",
        "    acts = batch_actions[idx]\n",
        "    tmp_str = string_ops.regex_replace(x,DEFAULT_STRIP_REGEX,'')\n",
        "    tmp_str = str(tmp_str.numpy(), 'utf-8').strip()\n",
        "    tmp_list = [i for i in tmp_str.split(' ') if i]\n",
        "    if (len(tmp_list) > len(acts)):\n",
        "      print(\"ERROR: REGEX INSUFFICIENT\")\n",
        "      sys.exit()\n",
        "    new_list = []\n",
        "    addct=0\n",
        "    for i,toke in enumerate(tmp_list):\n",
        "      if acts[i] != 1:\n",
        "        new_list.append(toke)\n",
        "    new_X.append(' '.join(new_list))\n",
        "    if idx==0: \n",
        "      print(\"\\tsentence action and word-removal time : \",time.time()-start)\n",
        "      # print(X[0])\n",
        "      # print(new_X[0])\n",
        "  return batch_logits, new_X, log_prob_sums\n",
        "\n",
        "# from tensorflow.compat.v1.distributions import Multinomial as multinomial\n",
        "'''\n",
        "tf.random.categorical(logits=np.array([[.1,.2,.9]]),num_samples=1)\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import time\n",
        "# \n",
        "# policy gradient (REINFORCE) training loop with LSTM model and BERT sentiment classifier\n",
        "# classifier must be compiled!\n",
        "# \n",
        "def train_vpg_mlp(mlp, optimizer, classifier, training_set, validation_set, epochs=5):\n",
        "  total_start=time.time()\n",
        "  stepct=0\n",
        "  # with tf.device('/device:GPU:0'):\n",
        "  for e in range(epochs):\n",
        "    epoch_losses=[]\n",
        "    counter=0\n",
        "    trainlen = len(training_set)\n",
        "    for idx,ex_lab in enumerate(training_set):\n",
        "    # for idx,ex_lab in enumerate(training_set.take(100)):\n",
        "      starttime=time.time()\n",
        "      example, label = ex_lab[0], ex_lab[1]\n",
        "      counter+=1\n",
        "      print('epoch={}\\tbatch={}'.format(e,counter))\n",
        "      stepct+=1\n",
        "      # run through the lstm\n",
        "      logits, new_example, logprob_sums = None, None, None\n",
        "      with tf.GradientTape() as t:\n",
        "        start = time.time()\n",
        "        # logits, new_example, logprob_sums = step(lstm, example)\n",
        "        # logits, new_example, logprob_sums = step2(lstm, example)\n",
        "        logits, new_example, logprob_sums = mlpstep2(mlp, example)\n",
        "        # logging for curiosity\n",
        "        if e==0 and idx==0:\n",
        "          print('step time for one batch: {:.4f}'.format(time.time()-start))\n",
        "\n",
        "        # get BERT evaluations on these\n",
        "        start=time.time()\n",
        "        new_outs = classifier(tf.constant(new_example))\n",
        "        # get bert evaluation on full sentences\n",
        "        baseline_outs = classifier(example)\n",
        "\n",
        "        if e==0 and idx==0:\n",
        "          print('BERT processing time for one batch : {:.4f}'.format(time.time()-start))\n",
        "\n",
        "        # reward LSTM with the improvement over the original sentences\n",
        "        baseline_loss = tf.keras.losses.mean_squared_error(baseline_outs,tf.cast(label,float))\n",
        "        loss_object = tf.keras.losses.mean_squared_error(new_outs,tf.cast(label,float))\n",
        "        # loss_object = tf.keras.losses.binary_crossentropy(new_outs,tf.cast(label,float))\n",
        "        adjusted_loss = loss_object-baseline_loss\n",
        "        # print(\"loss_x' - loss_base : \",np.array(adjusted_loss))\n",
        "        epoch_losses.append(adjusted_loss.numpy())\n",
        "\n",
        "        # use BERT's loss for update:\n",
        "        # use the negative losses to weight the log_probs\n",
        "        weighted_logprobs = -(adjusted_loss)*logprob_sums\n",
        "        # end with tf.GradientTape()\n",
        "\n",
        "      # train bert by fitting on new_examples\n",
        "      # this way, BERT and the LSTM train together\n",
        "      with tf.device('/device:GPU:0'):\n",
        "        history = classifier.fit(x=tf.constant(new_example),\n",
        "                                  y=label,\n",
        "                                  validation_split=.2,\n",
        "                                  batch_size=len(new_example),\n",
        "                                  epochs=2,\n",
        "                                  verbose=1)\n",
        "      # print(\"BERT training accuracy : \", np.mean(history.history['binary_accuracy']))\n",
        "\n",
        "      # get gradients and apply update\n",
        "      gradients = t.gradient(weighted_logprobs, mlp.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients,mlp.trainable_variables))\n",
        "      if idx == 1: print('batch time {:.2f}'.format(time.time()-starttime))\n",
        "      # end for\n",
        "    print('\\n_____________________________')\n",
        "    print('[{}]\\t avg training loss : {}'.format(e,np.mean(epoch_losses)))\n",
        "    # print('[{}]\\t total train inloss : {}'.format(e,np.sum(epoch_losses)))\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      val_loss, val_acc = classifier.evaluate(validation_set)\n",
        "    print(\"[{}] BERT validation loss     :\\t{}\\n\\t\\tvalidation accuracy :\\t{}\".format(idx,val_loss, val_acc))\n",
        "  print('DONE. {:.4f}'.format(time.time()-total_start))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1nGSuChF1xR"
      },
      "source": [
        "train_vpg_mlp(mlp_model, optimizer=, classifier_model, train_ds.take(10), val_ds, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}